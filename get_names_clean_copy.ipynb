{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint \n",
    "from time import time\n",
    "from collections import Counter\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import names as nltknames\n",
    "\n",
    "import igraph\n",
    "from igraph import Graph, EdgeSeq\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords = [sw for sw in stopwords if len(sw)>1]\n",
    "import json\n",
    "from nameit import Nameit, contains, filter_names, count_freq_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open(\"stop_words.txt\", 'w+', encoding='utf-8')\n",
    "fout.writelines('\\n'.join(stopwords))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3756"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_names = []\n",
    "with open('asian.txt') as f:\n",
    "    asiannames = f.readlines()\n",
    "last_names = [nm.strip().lower() for nm in asiannames]\n",
    "\n",
    "with open('white.txt') as f:\n",
    "    whitenames = f.readlines()\n",
    "last_names.extend([nm.strip().lower() for nm in whitenames])\n",
    "\n",
    "with open('top1000_lastnames.txt') as f:\n",
    "    topnames = f.readlines()\n",
    "last_names.extend([nm.strip().lower() for nm in topnames])\n",
    "\n",
    "last_names.sort()\n",
    "last_names = [ln for ln in last_names if ln!='']\n",
    "last_names = list(set(last_names))\n",
    "len(last_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = open(\"last_names_list.txt\", 'w+', encoding='utf-8')\n",
    "fout.writelines('\\n'.join(last_names))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = [name.lower() for name in nltknames.words()]\n",
    "first_names.sort()\n",
    "\n",
    "fout = open(\"first_names_list.txt\", 'w+', encoding='utf-8')\n",
    "fout.writelines('\\n'.join(first_names))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. get list of texts from different fields\n",
    "2. find items containig names (first or last) names\n",
    "3. count frequent words on the page excluding items containing names, found in step n2\n",
    "4. from most popular words create a filter list, if text field contains one of this words, it is not a name\n",
    "5. go thorugh all the text fields and filter them using filter list ( filter_names() function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get', 'list', 'of', 'texts', 'from', 'different', 'fields']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = \"get list of texts from different's fields\".split()\n",
    "\n",
    "names = [nm if not nm.endswith(\"'s\") else nm[:-2] for nm in names]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref = 'https://www.nobelprize.org/prizes/uncategorized/all-nobel-prizes-in-physics/'\n",
    "#ref = 'https://ballotpedia.org/List_of_current_members_of_the_U.S._Congress'\n",
    "#ref = 'https://www.congress.gov/members'\n",
    "\n",
    "#ref = 'https://chemistry.nd.edu/faculty-research/'\n",
    "#ref = 'https://www.chem.wisc.edu/people/faculty' # 'Badger Chemist',\n",
    "#ref = 'https://chbe.rice.edu/people/faculty'\n",
    "#ref = 'https://www.chem.uci.edu/people/faculty'\n",
    "ref = 'http://chemistry.mit.edu/people/faculty'\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'}\n",
    "page = requests.get(ref, headers = headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser') # type bs4.BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmx = Nameit(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = nmx.update_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you  -- in last names\n",
      "he  -- in last names\n",
      "her  -- in last names\n",
      "do  -- in last names\n",
      "an  -- in last names\n",
      "to  -- in last names\n",
      "in  -- in last names\n",
      "on  -- in last names\n",
      "no  -- in last names\n",
      "so  -- in last names\n",
      "than  -- in last names\n",
      "will\n",
      "don\n",
      "haven\n",
      "ma  -- in last names\n",
      "shan  -- in last names\n",
      "won  -- in last names\n"
     ]
    }
   ],
   "source": [
    "#exclude stopwords from last and first names\n",
    "sws = []\n",
    "for sw in stopwords:\n",
    "    if sw in nmx.first_names:\n",
    "        print(sw)\n",
    "        sws.append(sw)\n",
    "    elif sw in nmx.last_names:\n",
    "        print(sw + '  -- in last names')\n",
    "        sws.append(sw)\n",
    "\n",
    "for sw in sws:\n",
    "    nmx.first_names = list(filter(lambda x: x != sw, nmx.first_names))\n",
    "    nmx.last_names = list(filter(lambda x: x != sw, nmx.last_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schrock  Richard\n",
      "['schrock', 'richard']\n",
      "3 -- schrock\n",
      "1 -- richard\n"
     ]
    }
   ],
   "source": [
    "not_names = []\n",
    "known_names = []\n",
    "other_words = []\n",
    "\n",
    "punct_marks = \"\"\",.:;!?\"'\"\"\"\n",
    "\n",
    "#for txt in nmx.visible_texts:\n",
    "for txt in nmx.texts_from_tags:   \n",
    "    txt = txt.translate(dict.fromkeys(map(ord, punct_marks), ' ')) \n",
    "    words = txt.lower().strip().split()\n",
    "    words = [w.strip('-') for w in words]\n",
    "    \n",
    "    if 'hard' in txt.lower():\n",
    "        print(txt)\n",
    "        print(words)\n",
    "        pf = True\n",
    "    else:\n",
    "        pf = False\n",
    "    for w in words:\n",
    "        \n",
    "        if len(w) <=1:\n",
    "            continue\n",
    "        elif w[1]=='-':\n",
    "            w = w[2:]\n",
    "        \n",
    "        if w in nmx.name_prefixes:\n",
    "            continue\n",
    "        elif w in (nmx.last_names + nmx.first_names):\n",
    "            if pf: print('1 --', w)\n",
    "            known_names.append(w)\n",
    "            \n",
    "        elif w in nmx.common_words:\n",
    "            if pf: print('2 --', w)\n",
    "            not_names.append(w)\n",
    "        else:\n",
    "            if pf: print('3 --', w)\n",
    "            other_words.append(w)\n",
    "            \n",
    "            \n",
    "n_limit = 5\n",
    "\n",
    "freq_not_names, cntr = count_freq_words(not_names, n=1)\n",
    "\n",
    "freq_known_names, cntr2 = count_freq_words(known_names, n=0)\n",
    "\n",
    "freq_other_words, cntr3 = count_freq_words(other_words, n=4)\n",
    "\n",
    "questionable_names = []\n",
    "for wrd in freq_known_names:\n",
    "    if wrd.lower() in nmx.common_words:\n",
    "        questionable_names.append(wrd.lower())\n",
    "        \n",
    "too_often_names = []\n",
    "for wfreq in cntr2.most_common():\n",
    "    if (len(known_names)>100 and wfreq[1]>0.05*len(known_names)) or (len(known_names)<=100 and wfreq[1]>=5):\n",
    "        too_often_names.append(wfreq[0])\n",
    "        freq_known_names = list(filter(lambda x: x != wfreq[0], freq_known_names))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_not_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_not_names + too_often_names + freq_other_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalnames = []\n",
    "questionable_names_list = []\n",
    "\n",
    "xy = nmx.texts_from_tags\n",
    "for it in xy:\n",
    "    #if not contains(it, freq_known_names):\n",
    "    if contains(it, freq_not_names + too_often_names + freq_other_words + stopwords):\n",
    "        #print(it)\n",
    "        continue\n",
    "    if contains(it, questionable_names):\n",
    "        questionable_names_list.append(filter_names(it))\n",
    "        continue\n",
    "    nm = filter_names(it)\n",
    "    \n",
    "    if 'Main' in it:\n",
    "        print(it, filter_names(it))\n",
    "    if nm!='':\n",
    "        finalnames.append(nm)\n",
    "finalnames = list(set(finalnames))\n",
    "questionable_names_list = list(set(questionable_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_not_names + too_often_names + freq_other_words + stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Van Voorhis Troy', 'Field Robert']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionable_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalnames)\n",
    "# Deficit Reduction',\n",
    "# 'Job Opportunities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chakraborty Arup',\n",
       " 'Swager Timothy',\n",
       " 'Schrock Richard',\n",
       " 'Poster Printer',\n",
       " 'Nuclear Magnetic Resonance',\n",
       " 'Materials Nanoscience',\n",
       " 'Movassaghi Mohammad',\n",
       " 'Raines Ronald',\n",
       " 'Schlau-Cohen Gabriela',\n",
       " 'Johnson Jeremiah',\n",
       " 'Calendar Year Donors',\n",
       " 'Chemical Biology',\n",
       " 'Zhang Bin',\n",
       " 'Cao Jianshu',\n",
       " 'Danheiser Rick',\n",
       " 'Photo Credits',\n",
       " 'Fourier Transform Infrared Spectrometry',\n",
       " 'Alumni Association',\n",
       " 'Helpful Links',\n",
       " 'Additional Outreach',\n",
       " 'Kiessling Laura',\n",
       " 'Mass Spectrometry',\n",
       " 'Pentelute Bradley',\n",
       " 'Electron Paramagnetic Resonance',\n",
       " 'Finance Team',\n",
       " 'Radosevich Alexander',\n",
       " 'High Schools',\n",
       " 'Suess Daniel',\n",
       " 'Donor Profiles',\n",
       " 'Maps Directions',\n",
       " 'Administrative Assistants',\n",
       " 'Drennan Catherine',\n",
       " 'Willard Adam',\n",
       " 'Site Map',\n",
       " 'Dinca Mircea',\n",
       " 'Nelson Keith',\n",
       " 'Cummins Christopher',\n",
       " 'Hong Mei',\n",
       " 'Solomon Susan',\n",
       " 'Buchwald Stephen',\n",
       " 'Bawendi Moungi',\n",
       " 'Ceyer Sylvia',\n",
       " 'Community Relations',\n",
       " 'Giving Alumni',\n",
       " 'Online Application Instructions',\n",
       " 'Imperiali Barbara',\n",
       " 'Chemformation Newsletter',\n",
       " 'Nolan Elizabeth',\n",
       " 'Shoulders Matthew',\n",
       " 'Wendlandt Alison',\n",
       " 'Griffin Robert',\n",
       " 'Klibanov Alexander',\n",
       " 'Alumni Notes',\n",
       " 'Jamison Timothy',\n",
       " 'Elementary Schools',\n",
       " 'Growing Quality Crystals',\n",
       " 'Surendranath Yogesh',\n",
       " 'Shalek Alex',\n",
       " 'Essigmann John']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalnames"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "questionable_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chemistry',\n",
       " 'medicine',\n",
       " 'life',\n",
       " 'measurement',\n",
       " 'energy',\n",
       " 'organic',\n",
       " 'faculty',\n",
       " 'theory',\n",
       " 'of',\n",
       " 'search',\n",
       " 'research',\n",
       " 'university',\n",
       " 'science',\n",
       " 'department',\n",
       " 'contact',\n",
       " 'home',\n",
       " 'graduate']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_not_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.sort()\n",
    "for nm in nms:\n",
    "    print(nm)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'charles' in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 'https://www.nobelprize.org/prizes/uncategorized/all-nobel-prizes-in-physics/'\n",
    "ref2 = 'https://www.nobelprize.org/prizes/uncategorized/all-nobel-prizes-in-chemistry/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmprts = nameparts(cur_names, nltk_names, last_names)\n",
    "    return cur_names, nmprts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 'https://www.cies.org/fulbright-scholars'\n",
    "ref = 'https://ballotpedia.org/United_States_Senate'\n",
    "ref = 'https://ballotpedia.org/List_of_current_members_of_the_U.S._Congress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613 4\n"
     ]
    }
   ],
   "source": [
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'}\n",
    "page = requests.get(ref, headers = headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser') # type bs4.BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
